{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridworld with First Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the value function of policy\n",
    "import numpy as np\n",
    "\n",
    "# display output\n",
    "from random import uniform\n",
    "import time\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [[-1, 0], [0, 1], [1, 0], [0, -1]] #up, right, down, left = (clockwise from up) \n",
    "action_count = len(actions) # total number of actions\n",
    "gridSize = 5 # create a square grid of gridSize by gridSize\n",
    "state_count = gridSize*gridSize # total number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gridworld():\n",
    "    def __init__(self, gridSize):\n",
    "        self.valueMap = np.zeros((gridSize, gridSize))\n",
    "        self.states = [[i, j] for i in range(gridSize) for j in range(gridSize)]\n",
    "        self.size = gridSize\n",
    "        self.new_pos = [0, 0] # initialize new position for p_transition\n",
    "        self.pos_check = [0, 0] # a copy of new position\n",
    "        self.transition_prob = 1 # deterministic\n",
    "    \n",
    "    def initial_state(self):\n",
    "        # return initial state\n",
    "        return grid.states[gridSize*gridSize-1]\n",
    "       \n",
    "    def reward(self, current_pos, action):\n",
    "        # return the reward        \n",
    "        \n",
    "        # take action in current pos\n",
    "        self.new_pos = np.array(current_pos) + np.array(action)\n",
    "\n",
    "        # normally, reward = 0\n",
    "        reward = 0\n",
    "\n",
    "        # if new pos results in off the grid, return reward -1\n",
    "        if -1 in self.new_pos or self.size in self.new_pos:\n",
    "            reward = -1\n",
    "        # if in state A, transition to state A'\n",
    "        if current_pos == [0, 1]:\n",
    "            reward = 10\n",
    "        # if in state B, transition to state B'\n",
    "        if current_pos == [0, 3]:\n",
    "            reward = 5\n",
    "        return reward\n",
    "    \n",
    "    def p_transition(self, current_pos, action):\n",
    "        # return the transition probability\n",
    "        # get next position: state: [0, 0], action: [0, 1], new_state = [0, 1]\n",
    "        self.new_pos = np.array(current_pos) + np.array(action)\n",
    "        self.pos_check = self.new_pos # make a copy of new pos before being overwritten below\n",
    "\n",
    "        # if taking an action crosses the border = agent stays in same position\n",
    "        if -1 in self.new_pos or self.size in self.new_pos: \n",
    "            self.new_pos = current_pos\n",
    "            \n",
    "        # if in state A, transition to state A'\n",
    "        if current_pos == [0, 1]:\n",
    "            self.new_pos = [4, 1]\n",
    "            \n",
    "        # if in state B, transition to state B'\n",
    "        if current_pos == [0, 3]:\n",
    "            self.new_pos = [2, 3]\n",
    "        return self.new_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grid object\n",
    "grid = Gridworld(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get initial state (bottom right)\n",
    "grid.initial_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-visit MC Control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a random policy\n",
    "random_policy = np.random.randint(1000, size=(state_count, action_count))\n",
    "random_policy = random_policy/random_policy.sum(axis=1)[:,None]\n",
    "policy = random_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15957447, 0.17021277, 0.11930091, 0.55091185],\n",
       "       [0.21981308, 0.2235514 , 0.28635514, 0.27028037],\n",
       "       [0.27961433, 0.16115702, 0.30440771, 0.25482094],\n",
       "       [0.14693535, 0.39588581, 0.35138539, 0.10579345],\n",
       "       [0.31801471, 0.24522059, 0.14632353, 0.29044118],\n",
       "       [0.33765112, 0.42141623, 0.19905009, 0.04188256],\n",
       "       [0.18684461, 0.1115348 , 0.25357483, 0.44804576],\n",
       "       [0.41468927, 0.05875706, 0.39774011, 0.12881356],\n",
       "       [0.23833333, 0.325     , 0.155     , 0.28166667],\n",
       "       [0.60904449, 0.03792852, 0.34573304, 0.00729395],\n",
       "       [0.1125    , 0.19411765, 0.38823529, 0.30514706],\n",
       "       [0.17424564, 0.36464088, 0.16574586, 0.29536762],\n",
       "       [0.02671756, 0.18129771, 0.59160305, 0.20038168],\n",
       "       [0.08573718, 0.08092949, 0.44551282, 0.38782051],\n",
       "       [0.16755725, 0.29885496, 0.21870229, 0.3148855 ],\n",
       "       [0.31588367, 0.19105145, 0.10380313, 0.38926174],\n",
       "       [0.28959576, 0.22597747, 0.03843605, 0.44599072],\n",
       "       [0.27588235, 0.19823529, 0.03647059, 0.48941176],\n",
       "       [0.36697697, 0.04066634, 0.31945125, 0.27290544],\n",
       "       [0.34140969, 0.18226872, 0.03193833, 0.44438326],\n",
       "       [0.10818308, 0.26537217, 0.32038835, 0.3060564 ],\n",
       "       [0.14323144, 0.31834061, 0.27554585, 0.2628821 ],\n",
       "       [0.04337767, 0.5448236 , 0.37941006, 0.03238866],\n",
       "       [0.28781431, 0.29555126, 0.21818182, 0.19845261],\n",
       "       [0.27649088, 0.2454411 , 0.37999014, 0.09807787]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random policy\n",
    "policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Episode following policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial state\n",
    "state = grid.initial_state()\n",
    "\n",
    "# initialize state (with iniitial state), action list\n",
    "state_list = [state]\n",
    "action_list = []\n",
    "\n",
    "# generate an episode\n",
    "for i in range(10):\n",
    "    \n",
    "    # pick an action based on categorical distribution in policy\n",
    "    action = int(np.random.choice(action_count, 1, p=policy[grid.states.index(state)]))\n",
    "    action = actions[action]\n",
    "    \n",
    "    # get the new state with the chosen action\n",
    "    new_state = list(grid.p_transition(state, action))\n",
    "    state = new_state\n",
    "    \n",
    "    # save state and action to list\n",
    "    state_list.append(state)\n",
    "    action_list.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 4],\n",
       " [4, 4],\n",
       " [4, 4],\n",
       " [4, 4],\n",
       " [4, 4],\n",
       " [3, 4],\n",
       " [3, 3],\n",
       " [3, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [2, 2]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [-1, 0],\n",
       " [0, -1],\n",
       " [0, -1],\n",
       " [-1, 0],\n",
       " [0, -1],\n",
       " [0, 1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop for each steo of episode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 0\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma*G + grid.reward(state_list[-1], action_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
