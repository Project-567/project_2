{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: https://github.com/lazyprogrammer/machine_learning_examples/tree/master/rl\n",
    "# the Monte Carlo Epsilon-Greedy method to find the optimal policy and value function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from gridWorldGame import standard_grid, negative_grid,print_values, print_policy\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid: # Environment\n",
    "  def __init__(self, width, height, start):\n",
    "    self.width = width\n",
    "    self.height = height\n",
    "    self.i = start[0]\n",
    "    self.j = start[1]\n",
    "\n",
    "  def set(self, rewards, actions):\n",
    "    # rewards should be a dict of: (i, j): r (row, col): reward\n",
    "    # actions should be a dict of: (i, j): A (row, col): list of possible actions\n",
    "    self.rewards = rewards\n",
    "    self.actions = actions\n",
    "\n",
    "  def set_state(self, s):\n",
    "    self.i = s[0]\n",
    "    self.j = s[1]\n",
    "\n",
    "  def current_state(self):\n",
    "    return (self.i, self.j)\n",
    "\n",
    "  def is_terminal(self, s):\n",
    "    return s not in self.actions\n",
    "\n",
    "  def move(self, action):\n",
    "    # check if legal move first\n",
    "    if action in self.actions[(self.i, self.j)]:\n",
    "      if action == 'U':\n",
    "        self.i -= 1\n",
    "      elif action == 'D':\n",
    "        self.i += 1\n",
    "      elif action == 'R':\n",
    "        self.j += 1\n",
    "      elif action == 'L':\n",
    "        self.j -= 1\n",
    "    # return a reward (if any)\n",
    "    return self.rewards.get((self.i, self.j), 0)\n",
    "\n",
    "  def undo_move(self, action):\n",
    "    # these are the opposite of what U/D/L/R should normally do\n",
    "    if action == 'U':\n",
    "      self.i += 1\n",
    "    elif action == 'D':\n",
    "      self.i -= 1\n",
    "    elif action == 'R':\n",
    "      self.j -= 1\n",
    "    elif action == 'L':\n",
    "      self.j += 1\n",
    "    # raise an exception if we arrive somewhere we shouldn't be\n",
    "    # should never happen\n",
    "    assert(self.current_state() in self.all_states())\n",
    "\n",
    "  def game_over(self):\n",
    "    # returns true if game is over, else false\n",
    "    # true if we are in a state where no actions are possible\n",
    "    return (self.i, self.j) not in self.actions\n",
    "\n",
    "  def all_states(self):\n",
    "    # possibly buggy but simple way to get all states\n",
    "    # either a position that has possible next actions\n",
    "    # or a position that yields a reward\n",
    "    return set(self.actions.keys()) | set(self.rewards.keys())\n",
    "\n",
    "\n",
    "def standard_grid():\n",
    "  # define a grid that describes the reward for arriving at each state\n",
    "  # and possible actions at each state\n",
    "  # the grid looks like this\n",
    "  # x means you can't go there\n",
    "  # s means start position\n",
    "  # number means reward at that state\n",
    "  # .  .  .  1\n",
    "  # .  x  . -1\n",
    "  # s  .  .  .\n",
    "  g = Grid(3, 4, (2, 0))\n",
    "  rewards = {(0, 3): 1, (1, 3): -1}\n",
    "  actions = {\n",
    "    (0, 0): ('D', 'R'),\n",
    "    (0, 1): ('L', 'R'),\n",
    "    (0, 2): ('L', 'D', 'R'),\n",
    "    (1, 0): ('U', 'D'),\n",
    "    (1, 2): ('U', 'D', 'R'),\n",
    "    (2, 0): ('U', 'R'),\n",
    "    (2, 1): ('L', 'R'),\n",
    "    (2, 2): ('L', 'R', 'U'),\n",
    "    (2, 3): ('L', 'U'),\n",
    "  }\n",
    "  g.set(rewards, actions)\n",
    "  return g\n",
    "\n",
    "\n",
    "def negative_grid(step_cost=-0.1):\n",
    "  # in this game we want to try to minimize the number of moves\n",
    "  # so we will penalize every move\n",
    "  g = standard_grid()\n",
    "  g.rewards.update({\n",
    "    (0, 0): step_cost,\n",
    "    (0, 1): step_cost,\n",
    "    (0, 2): step_cost,\n",
    "    (1, 0): step_cost,\n",
    "    (1, 2): step_cost,\n",
    "    (2, 0): step_cost,\n",
    "    (2, 1): step_cost,\n",
    "    (2, 2): step_cost,\n",
    "    (2, 3): step_cost,\n",
    "  })\n",
    "  return g\n",
    "\n",
    "\n",
    "def print_values(V, g):\n",
    "  for i in range(g.width):\n",
    "    print(\"---------------------------\")\n",
    "    for j in range(g.height):\n",
    "      v = V.get((i,j), 0)\n",
    "      if v >= 0:\n",
    "        print(\" %.2f|\" % v, end=\"\")\n",
    "      else:\n",
    "        print(\"%.2f|\" % v, end=\"\") # -ve sign takes up an extra space\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def print_policy(P, g):\n",
    "  for i in range(g.width):\n",
    "    print(\"---------------------------\")\n",
    "    for j in range(g.height):\n",
    "      a = P.get((i,j), ' ')\n",
    "      print(\"  %s  |\" % a, end=\"\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.1):\n",
    "  # choose given a with probability 1 - eps + eps/4\n",
    "  p = np.random.random()\n",
    "  if p < (1 - eps):\n",
    "    return a\n",
    "  else:\n",
    "    return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "  # returns the argmax (key) and max (value) from a dictionary\n",
    "  max_key = None\n",
    "  max_val = float('-inf')\n",
    "  for k, v in d.items():\n",
    "    if v > max_val:\n",
    "      max_val = v\n",
    "      max_key = k\n",
    "  return max_key, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(grid, policy):\n",
    "  # returns a list of states and corresponding returns\n",
    "  # use an epsilon-soft policy\n",
    "  s = (2, 0)\n",
    "  grid.set_state(s)\n",
    "  a = random_action(policy[s])\n",
    "\n",
    "  # each triple is s(t), a(t), r(t)\n",
    "  # but r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
    "  states_actions_rewards = [(s, a, 0)]\n",
    "  while True:\n",
    "    r = grid.move(a)\n",
    "    s = grid.current_state()\n",
    "    if grid.game_over():\n",
    "      states_actions_rewards.append((s, None, r))\n",
    "      break\n",
    "    else:\n",
    "      a = random_action(policy[s]) # the next state is stochastic\n",
    "      states_actions_rewards.append((s, a, r))\n",
    "\n",
    "  # calculate the returns by working backwards from the terminal state\n",
    "  G = 0\n",
    "  states_actions_returns = []\n",
    "  first = True\n",
    "  for s, a, r in reversed(states_actions_rewards):\n",
    "    # the value of the terminal state is 0 by definition\n",
    "    # we should ignore the first state we encounter\n",
    "    # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
    "    if first:\n",
    "      first = False\n",
    "    else:\n",
    "      states_actions_returns.append((s, a, G))\n",
    "    G = r + GAMMA*G\n",
    "  states_actions_returns.reverse() # we want it to be in order of state visited\n",
    "  return states_actions_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n"
     ]
    }
   ],
   "source": [
    "grid = negative_grid(step_cost=-0.1)\n",
    "# print rewards\n",
    "print(\"rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial policy:\n",
      "---------------------------\n",
      "  R  |  U  |  R  |     |\n",
      "---------------------------\n",
      "  R  |     |  R  |     |\n",
      "---------------------------\n",
      "  L  |  D  |  U  |  D  |\n"
     ]
    }
   ],
   "source": [
    "# state -> action\n",
    "# initialize a random policy\n",
    "policy = {}\n",
    "for s in grid.actions.keys():\n",
    "  policy[s] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "  \n",
    "# initial policy\n",
    "print(\"initial policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): {'D': 0, 'R': 0, 'L': 0, 'U': 0}, (1, 2): {'D': 0, 'R': 0, 'L': 0, 'U': 0}, (0, 0): {'D': 0, 'R': 0, 'L': 0, 'U': 0}, (2, 3): {'D': 0, 'R': 0, 'L': 0, 'U': 0}, (2, 0): {'D': 0, 'R': 0, 'L': 0, 'U': 0}, (1, 0): {'D': 0, 'R': 0, 'L': 0, 'U': 0}, (2, 2): {'D': 0, 'R': 0, 'L': 0, 'U': 0}, (0, 2): {'D': 0, 'R': 0, 'L': 0, 'U': 0}, (2, 1): {'D': 0, 'R': 0, 'L': 0, 'U': 0}}\n"
     ]
    }
   ],
   "source": [
    "# initialize Q(s,a) and returns\n",
    "Q = {}\n",
    "returns = {} # dictionary of state -> list of returns we've received\n",
    "states = grid.all_states()\n",
    "for s in states:\n",
    "  if s in grid.actions: # not a terminal state\n",
    "    Q[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "      Q[s][a] = 0\n",
    "      returns[(s,a)] = []\n",
    "  else:\n",
    "    # terminal state or state we can't otherwise get to\n",
    "    pass\n",
    "  \n",
    "# initial Q values for all states in grid\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat\n",
    "deltas = []\n",
    "for t in range(5000):\n",
    "  # generate an episode using pi\n",
    "  biggest_change = 0\n",
    "  states_actions_returns = play_game(grid, policy)\n",
    "\n",
    "  # calculate Q(s,a)\n",
    "  seen_state_action_pairs = set()\n",
    "  for s, a, G in states_actions_returns:\n",
    "    # check if we have already seen s\n",
    "    # called \"first-visit\" MC policy evaluation\n",
    "    sa = (s, a)\n",
    "    if sa not in seen_state_action_pairs:\n",
    "      old_q = Q[s][a]\n",
    "      returns[sa].append(G)\n",
    "      Q[s][a] = np.mean(returns[sa])\n",
    "      biggest_change = max(biggest_change, np.abs(old_q - Q[s][a]))\n",
    "      seen_state_action_pairs.add(sa)\n",
    "  deltas.append(biggest_change)\n",
    "\n",
    "  # calculate new policy pi(s) = argmax[a]{ Q(s,a) }\n",
    "  for s in policy.keys():\n",
    "    a, _ = max_dict(Q[s])\n",
    "    policy[s] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(deltas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.58| 0.78| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.41| 0.00| 0.75| 0.00|\n",
      "---------------------------\n",
      " 0.25| 0.10|-0.13| 0.00|\n"
     ]
    }
   ],
   "source": [
    "# find the optimal state-value function\n",
    "# V(s) = max[a]{ Q(s,a) }\n",
    "V = {}\n",
    "for s in policy.keys():\n",
    "  V[s] = max_dict(Q[s])[1]\n",
    "\n",
    "print(\"final values:\")\n",
    "print_values(V, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  L  |  L  |  L  |\n"
     ]
    }
   ],
   "source": [
    "print(\"final policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
